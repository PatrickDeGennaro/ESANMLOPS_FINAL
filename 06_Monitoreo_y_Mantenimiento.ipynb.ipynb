{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73ae7ec7-dd71-463f-a265-57906b4fd3bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este notebook forma parte del trabajo final del curso de MLOps en el Diplomado de Data Analytics de ESAN y aborda la fase de monitoreo y mantenimiento de un modelo en producción. Su objetivo es evaluar el desempeño del modelo con datos nuevos y detectar posibles cambios en la distribución de las variables (data drift) que puedan afectar su precisión.\n",
    "\n",
    "Para ello, se cargan datos históricos y recientes, verificando la consistencia de las columnas clave. Se analiza el data drift mediante estadísticas descriptivas y el test de Kolmogorov-Smirnov. Luego, se evalúa el modelo en los nuevos datos usando la métrica AUC (Area Under the Curve).Finalmente, los resultados se almacenan en MLflow, y se establece un sistema de alertas para identificar caídas en la precisión y determinar si es necesario reentrenar o ajustar el modelo. Este proceso es clave en MLOps para asegurar la confiabilidad del modelo en producción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdec74a8-6446-492f-a21b-83faa04cf364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Inicialización del entorno y librerías\n",
    "En este primer paso, se importan las librerías necesarias para la sesión de Spark, MLflow y el análisis de data drift.\n",
    "Se inicia la sesión de Spark y se imprime un mensaje para indicar que el notebook ha sido cargado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a7cf54-9f6a-491e-a41c-9a9f6a05906d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 06 - Monitoreo y Mantenimiento - iniciado.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import time\n",
    "\n",
    "# Librerías opcionales para data drift\n",
    "from pyspark.ml.stat import KolmogorovSmirnovTest\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"Notebook 06 - Monitoreo y Mantenimiento - iniciado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b41d67-7b17-4580-b032-f8f9f66c286d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Carga de datos históricos y datos recientes\n",
    "Se cargan dos conjuntos de datos:\n",
    "df_train: Datos de entrenamiento usados previamente en la fase de modelado.\n",
    "df_new: Un subconjunto aleatorio de df_train, simulado para representar nuevos datos post-producción.\n",
    "Se comparan los tamaños de ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c36088bc-5424-4877-b98d-0c2ea0be98c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train registros: 10000\ndf_new (simulados) registros: 1006\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Accident_Occurred</th><th>Hours_Worked</th><th>Weather_Risk_Index</th><th>Machine_Age_Years</th><th>Employee_Experience_Years</th><th>Safety_Violations</th><th>Inspection_Frequency</th><th>Job_Risk_Level</th><th>Shift_Type</th><th>Area</th><th>Employee_Age</th><th>Noise_Level_dB</th><th>Temperature_C</th><th>features</th><th>scaled_features</th><th>Moving_Avg_Noise</th><th>Moving_Avg_Temperature</th><th>Diff_Safety_Violations</th><th>Diff_Inspection_Frequency</th><th>Age_Group</th></tr></thead><tbody><tr><td>0</td><td>7</td><td>0.7876088143823133</td><td>1</td><td>9</td><td>9</td><td>11</td><td>2</td><td>0</td><td>0</td><td>18</td><td>97.82037145789187</td><td>32.299454658105226</td><td>Map(vectorType -> dense, length -> 10, values -> List(7.0, 0.7876088143823133, 1.0, 9.0, 9.0, 11.0, 2.0, 18.0, 97.82037145789187, 32.299454658105226))</td><td>Map(vectorType -> dense, length -> 10, values -> List(-0.8772547561736581, 0.9920654263915089, -1.6235212602055429, -0.6389558183766151, 1.5662941927316953, 1.5835148358060784, 0.7448507855134497, -1.7034203426534413, 1.5786643044219437, 0.8490793014224517))</td><td>89.86964217028178</td><td>29.798136636343173</td><td>4</td><td>10</td><td>Joven</td></tr><tr><td>0</td><td>9</td><td>0.5691529759659067</td><td>13</td><td>25</td><td>3</td><td>11</td><td>1</td><td>0</td><td>1</td><td>18</td><td>93.17319493801877</td><td>30.35915084752571</td><td>Map(vectorType -> dense, length -> 10, values -> List(9.0, 0.5691529759659067, 13.0, 25.0, 3.0, 11.0, 1.0, 18.0, 93.17319493801877, 30.35915084752571))</td><td>Map(vectorType -> dense, length -> 10, values -> List(0.3020888697907859, 0.24198032379971338, 0.5640705476574821, 1.2098078067139635, -0.5164515092296965, 1.5835148358060784, -0.7392113494007705, -1.7034203426534413, 1.2570722285583302, 0.6246834933390406))</td><td>81.84400007944413</td><td>30.19145795891655</td><td>1</td><td>2</td><td>Joven</td></tr><tr><td>1</td><td>8</td><td>0.9471685115785861</td><td>10</td><td>16</td><td>7</td><td>5</td><td>1</td><td>0</td><td>0</td><td>18</td><td>74.67027611156388</td><td>24.006433896303236</td><td>Map(vectorType -> dense, length -> 10, values -> List(8.0, 0.9471685115785861, 10.0, 16.0, 7.0, 5.0, 1.0, 18.0, 74.67027611156388, 24.006433896303236))</td><td>Map(vectorType -> dense, length -> 10, values -> List(-0.2875829431914361, 1.539926049886722, 0.017172595691725853, 0.16987826760051303, 0.8720456254112313, -0.3160950919843262, -0.7392113494007705, -1.7034203426534413, -0.023359459261018917, -0.11000714944694003))</td><td>76.46893671186487</td><td>28.215117972436804</td><td>7</td><td>1</td><td>Joven</td></tr><tr><td>0</td><td>9</td><td>0.6671909163791936</td><td>15</td><td>23</td><td>4</td><td>4</td><td>2</td><td>0</td><td>1</td><td>18</td><td>54.982460511532395</td><td>20.689619082630813</td><td>Map(vectorType -> dense, length -> 10, values -> List(9.0, 0.6671909163791936, 15.0, 23.0, 4.0, 4.0, 2.0, 18.0, 54.982460511532395, 20.689619082630813))</td><td>Map(vectorType -> dense, length -> 10, values -> List(0.3020888697907859, 0.5786012130643776, 0.9286691823013197, 0.9787123535776412, -0.16932722556946456, -0.6326967466160603, 0.7448507855134497, -1.7034203426534413, -1.3857879060735043, -0.4935962226213912))</td><td>58.89418221459263</td><td>20.69038495613166</td><td>-5</td><td>-7</td><td>Joven</td></tr><tr><td>0</td><td>7</td><td>0.22834059818324426</td><td>4</td><td>23</td><td>6</td><td>8</td><td>1</td><td>0</td><td>1</td><td>18</td><td>61.86593677005129</td><td>22.174688437542187</td><td>Map(vectorType -> dense, length -> 10, values -> List(7.0, 0.22834059818324426, 4.0, 23.0, 6.0, 8.0, 1.0, 18.0, 61.86593677005129, 22.174688437542187))</td><td>Map(vectorType -> dense, length -> 10, values -> List(-0.8772547561736581, -0.9282254679373826, -1.0766233082397867, 0.9787123535776412, 0.5249213417509994, 0.6337098719108761, -0.7392113494007705, -1.7034203426534413, -0.9094402980864851, -0.32184820247205315))</td><td>71.33539614618614</td><td>29.76576504290782</td><td>-3</td><td>1</td><td>Joven</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         7,
         0.7876088143823133,
         1,
         9,
         9,
         11,
         2,
         0,
         0,
         18,
         97.82037145789187,
         32.299454658105226,
         {
          "length": 10,
          "values": [
           7.0,
           0.7876088143823133,
           1.0,
           9.0,
           9.0,
           11.0,
           2.0,
           18.0,
           97.82037145789187,
           32.299454658105226
          ],
          "vectorType": "dense"
         },
         {
          "length": 10,
          "values": [
           -0.8772547561736581,
           0.9920654263915089,
           -1.6235212602055429,
           -0.6389558183766151,
           1.5662941927316953,
           1.5835148358060784,
           0.7448507855134497,
           -1.7034203426534413,
           1.5786643044219437,
           0.8490793014224517
          ],
          "vectorType": "dense"
         },
         89.86964217028178,
         29.798136636343173,
         4,
         10,
         "Joven"
        ],
        [
         0,
         9,
         0.5691529759659067,
         13,
         25,
         3,
         11,
         1,
         0,
         1,
         18,
         93.17319493801877,
         30.35915084752571,
         {
          "length": 10,
          "values": [
           9.0,
           0.5691529759659067,
           13.0,
           25.0,
           3.0,
           11.0,
           1.0,
           18.0,
           93.17319493801877,
           30.35915084752571
          ],
          "vectorType": "dense"
         },
         {
          "length": 10,
          "values": [
           0.3020888697907859,
           0.24198032379971338,
           0.5640705476574821,
           1.2098078067139635,
           -0.5164515092296965,
           1.5835148358060784,
           -0.7392113494007705,
           -1.7034203426534413,
           1.2570722285583302,
           0.6246834933390406
          ],
          "vectorType": "dense"
         },
         81.84400007944413,
         30.19145795891655,
         1,
         2,
         "Joven"
        ],
        [
         1,
         8,
         0.9471685115785861,
         10,
         16,
         7,
         5,
         1,
         0,
         0,
         18,
         74.67027611156388,
         24.006433896303236,
         {
          "length": 10,
          "values": [
           8.0,
           0.9471685115785861,
           10.0,
           16.0,
           7.0,
           5.0,
           1.0,
           18.0,
           74.67027611156388,
           24.006433896303236
          ],
          "vectorType": "dense"
         },
         {
          "length": 10,
          "values": [
           -0.2875829431914361,
           1.539926049886722,
           0.017172595691725853,
           0.16987826760051303,
           0.8720456254112313,
           -0.3160950919843262,
           -0.7392113494007705,
           -1.7034203426534413,
           -0.023359459261018917,
           -0.11000714944694003
          ],
          "vectorType": "dense"
         },
         76.46893671186487,
         28.215117972436804,
         7,
         1,
         "Joven"
        ],
        [
         0,
         9,
         0.6671909163791936,
         15,
         23,
         4,
         4,
         2,
         0,
         1,
         18,
         54.982460511532395,
         20.689619082630813,
         {
          "length": 10,
          "values": [
           9.0,
           0.6671909163791936,
           15.0,
           23.0,
           4.0,
           4.0,
           2.0,
           18.0,
           54.982460511532395,
           20.689619082630813
          ],
          "vectorType": "dense"
         },
         {
          "length": 10,
          "values": [
           0.3020888697907859,
           0.5786012130643776,
           0.9286691823013197,
           0.9787123535776412,
           -0.16932722556946456,
           -0.6326967466160603,
           0.7448507855134497,
           -1.7034203426534413,
           -1.3857879060735043,
           -0.4935962226213912
          ],
          "vectorType": "dense"
         },
         58.89418221459263,
         20.69038495613166,
         -5,
         -7,
         "Joven"
        ],
        [
         0,
         7,
         0.22834059818324426,
         4,
         23,
         6,
         8,
         1,
         0,
         1,
         18,
         61.86593677005129,
         22.174688437542187,
         {
          "length": 10,
          "values": [
           7.0,
           0.22834059818324426,
           4.0,
           23.0,
           6.0,
           8.0,
           1.0,
           18.0,
           61.86593677005129,
           22.174688437542187
          ],
          "vectorType": "dense"
         },
         {
          "length": 10,
          "values": [
           -0.8772547561736581,
           -0.9282254679373826,
           -1.0766233082397867,
           0.9787123535776412,
           0.5249213417509994,
           0.6337098719108761,
           -0.7392113494007705,
           -1.7034203426534413,
           -0.9094402980864851,
           -0.32184820247205315
          ],
          "vectorType": "dense"
         },
         71.33539614618614,
         29.76576504290782,
         -3,
         1,
         "Joven"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Accident_Occurred",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Hours_Worked",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Weather_Risk_Index",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Machine_Age_Years",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Employee_Experience_Years",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Safety_Violations",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Inspection_Frequency",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Job_Risk_Level",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Shift_Type",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Area",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Employee_Age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Noise_Level_dB",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Temperature_C",
         "type": "\"double\""
        },
        {
         "metadata": "{\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":0,\"name\":\"Hours_Worked\"},{\"idx\":1,\"name\":\"Weather_Risk_Index\"},{\"idx\":2,\"name\":\"Machine_Age_Years\"},{\"idx\":3,\"name\":\"Employee_Experience_Years\"},{\"idx\":4,\"name\":\"Safety_Violations\"},{\"idx\":5,\"name\":\"Inspection_Frequency\"},{\"idx\":6,\"name\":\"Job_Risk_Level\"},{\"idx\":7,\"name\":\"Employee_Age\"},{\"idx\":8,\"name\":\"Noise_Level_dB\"},{\"idx\":9,\"name\":\"Temperature_C\"}]},\"num_attrs\":10}}",
         "name": "features",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{\"ml_attr\":{\"num_attrs\":10}}",
         "name": "scaled_features",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{}",
         "name": "Moving_Avg_Noise",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Moving_Avg_Temperature",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Diff_Safety_Violations",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Diff_Inspection_Frequency",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Age_Group",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 2) Cargar datos de entrenamiento y nuevo dataset simulado\n",
    "# =========================================================\n",
    "\n",
    "# 2.1 Cargar df_train \n",
    "#     Aquí lo simulamos con la tabla de antes:\n",
    "df_train = spark.table(\"mining.safety_analysis.cleaned_mining_data\")\n",
    "\n",
    "# 2.2 Cargar un df_new que simula los datos \"recientes\" \n",
    "#     (post-producción). \n",
    "#     Aquí creamos un subset al azar para simularlo:\n",
    "df_new = df_train.sample(fraction=0.1, seed=999).cache()\n",
    "\n",
    "print(\"df_train registros:\", df_train.count())\n",
    "print(\"df_new (simulados) registros:\", df_new.count())\n",
    "\n",
    "display(df_new.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4204a8f-cc68-45e9-95a9-f555083fa135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Verificación de columnas relevantes\n",
    "Antes de analizar los datos, se aseguran de que las columnas clave del modelo estén presentes en df_new.\n",
    "Si faltan columnas esenciales, se lanza un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37dd9061-1b9e-4eda-91f1-f9b5c7f641ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en df_new: ['Accident_Occurred', 'Hours_Worked', 'Weather_Risk_Index', 'Machine_Age_Years', 'Employee_Experience_Years', 'Safety_Violations', 'Inspection_Frequency', 'Job_Risk_Level', 'Shift_Type', 'Area', 'Employee_Age', 'Noise_Level_dB', 'Temperature_C', 'features', 'scaled_features', 'Moving_Avg_Noise', 'Moving_Avg_Temperature', 'Diff_Safety_Violations', 'Diff_Inspection_Frequency', 'Age_Group']\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 3) Verificar columnas relevantes\n",
    "# =========================================================\n",
    "# Suponemos que las 8 features y la label \n",
    "feature_cols = [\n",
    "    \"Shift_Type\",\n",
    "    \"Weather_Risk_Index\",\n",
    "    \"Job_Risk_Level\",\n",
    "    \"Hours_Worked\",\n",
    "    \"Employee_Experience_Years\",\n",
    "    \"Safety_Violations\",\n",
    "    \"Inspection_Frequency\",\n",
    "    \"Temperature_C\"\n",
    "]\n",
    "label_col = \"Accident_Occurred\"\n",
    "\n",
    "print(\"Columnas en df_new:\", df_new.columns)\n",
    "\n",
    "# Asegurarnos que df_new contenga esas columnas\n",
    "missing_cols = [c for c in feature_cols + [label_col] if c not in df_new.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"df_new no tiene columnas: {missing_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a48a20-2fca-45ff-aa33-3847f31e6e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Análisis de Data Drift con Kolmogorov-Smirnov\n",
    "Se compara la distribución de una variable clave (Weather_Risk_Index) entre df_train y df_new usando el test de Kolmogorov-Smirnov.\n",
    "Si la diferencia de medias es significativa, se alerta sobre posible data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36025d04-797f-46ac-85f7-bfbe9fe14d81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas (train): [Row(summary='count', Weather_Risk_Index='10000'), Row(summary='mean', Weather_Risk_Index='0.4986782867162684'), Row(summary='stddev', Weather_Risk_Index='0.2912414040241146'), Row(summary='min', Weather_Risk_Index='2.334951493544457E-4'), Row(summary='max', Weather_Risk_Index='0.9999300425196784')]\nEstadísticas (new): [Row(summary='count', Weather_Risk_Index='1006'), Row(summary='mean', Weather_Risk_Index='0.4952895500112074'), Row(summary='stddev', Weather_Risk_Index='0.2847381397932316'), Row(summary='min', Weather_Risk_Index='0.004117857299994809'), Row(summary='max', Weather_Risk_Index='0.9978868110445832')]\nMean drift en Weather_Risk_Index: 0.4986782867162684 -> 0.4952895500112074, diff=0.003\nNo se detectó drift significativo (mean).\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 4) Data Drift (básico) - Comparar distribuciones\n",
    "# =========================================================\n",
    "# Usamos KolmogorovSmirnovTest para comparar la distribución\n",
    "# de una sola columna en 'df_train' vs 'df_new'.\n",
    "# Como ejemplo, medimos drift en 'Weather_Risk_Index'.\n",
    "\n",
    "col_drift = \"Weather_Risk_Index\"\n",
    "\n",
    "# Nota: KolmogorovSmirnovTest requiere un RDD o DataFrame \n",
    "# con una sola columna, sin nulos:\n",
    "train_col_df = df_train.select(col_drift).dropna()\n",
    "new_col_df   = df_new.select(col_drift).dropna()\n",
    "\n",
    "# Convertir a double si no lo es\n",
    "train_col_df = train_col_df.withColumn(col_drift, F.col(col_drift).cast(\"double\"))\n",
    "new_col_df   = new_col_df.withColumn(col_drift, F.col(col_drift).cast(\"double\"))\n",
    "\n",
    "# Para KSTest, Spark ML 3.0+ hace:\n",
    "# KolmogorovSmirnovTest.test() -> solo sirve con un DataFrame con 2 col: \"features\", \"label\"\n",
    "# Lo ideal es transformar en \"features\" la variable.\n",
    "# Simplificaremos -> un approach typical es recabar stats y comparar manualmente.\n",
    "\n",
    "train_stats = train_col_df.describe().collect()\n",
    "new_stats   = new_col_df.describe().collect()\n",
    "\n",
    "print(\"Estadísticas (train):\", train_stats)\n",
    "print(\"Estadísticas (new):\", new_stats)\n",
    "\n",
    "# EJEMPLO: Compare la media\n",
    "# Convertir a float:\n",
    "def get_mean_from_describe(describe_rows):\n",
    "    # describe_rows es una lista de Row, buscaremos row donde summary='mean'\n",
    "    for r in describe_rows:\n",
    "        if r[\"summary\"] == \"mean\":\n",
    "            return float(r[col_drift])\n",
    "    return None\n",
    "\n",
    "mean_train = get_mean_from_describe(train_stats)\n",
    "mean_new   = get_mean_from_describe(new_stats)\n",
    "\n",
    "drift_diff = abs(mean_new - mean_train)\n",
    "print(f\"Mean drift en {col_drift}: {mean_train} -> {mean_new}, diff={drift_diff:.3f}\")\n",
    "\n",
    "# Si drift_diff es mayor a cierto umbral, consideras que hay data drift\n",
    "drift_threshold = 1.0  # Ejemplo\n",
    "if drift_diff > drift_threshold:\n",
    "    print(f\"⚠️ DRIFT DETECTADO en {col_drift}: cambio de media {drift_diff:.2f}\")\n",
    "else:\n",
    "    print(\"No se detectó drift significativo (mean).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc89be35-965d-45ef-8d46-6d03b2a698f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Evaluación del modelo en datos recientes\n",
    "Se carga el modelo de ML desde MLflow y se evalúa su desempeño en df_new usando el AUC como métrica de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "397e6377-56aa-4115-88a1-fd2b7c7814f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:60: SyntaxWarning: invalid escape sequence '\\.'\n  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\n/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:2570: SyntaxWarning: invalid escape sequence '\\.'\n  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\n/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:3431: SyntaxWarning: invalid escape sequence '\\.'\n  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\n2025/03/04 13:51:59 INFO mlflow.spark: 'models:/AccidentPrediction2025/1' resolved as 'abfss://unity-catalog-storage@dbstorageyp3hv5lr3xzh6.dfs.core.windows.net/1781258311325241/models/f0b5bfa6-b545-4a3a-8f96-eddccdc04e61/versions/74acc5b5-5c4b-414d-b811-03fa453d36b7'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC en df_new: 0.9829\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 5) Cargar la pipeline y evaluar performance en df_new\n",
    "# =========================================================\n",
    "# Asumiendo df_new también tiene la label 'Accident_Occurred' \n",
    "# (que llegó con retraso, por ejemplo).\n",
    "# Usaremos la pipeline final. \n",
    "# Ajustar 'models:/AccidentPrediction2025/1' o la stage \n",
    "# si ya está en Production.\n",
    "\n",
    "model_uri = \"models:/AccidentPrediction2025/1\"\n",
    "pipeline_model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "# Hacemos predicciones\n",
    "df_pred_new = pipeline_model.transform(df_new)\n",
    "\n",
    "# Evaluar AUC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "auc_new = evaluator.evaluate(df_pred_new)\n",
    "print(f\"AUC en df_new: {auc_new:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7ce052e-c702-4529-9ed6-b234ab54641b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Guardado de resultados y monitoreo continuo\n",
    "Se almacena el resultado del AUC en MLflow y se implementa una lógica básica de alerta si el rendimiento del modelo cae por debajo de un umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f3dafe6-ca56-4c43-b7a5-1d9c63f08084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Performance aceptable, no se requiere reentrenamiento.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 13:52:47 INFO mlflow.tracking._tracking_service.client: 🏃 View run Monitoring_in_Production at: adb-1781258311325241.1.azuredatabricks.net/ml/experiments/1516674257214703/runs/65f10f057f0f4932b210df1a49d8d1ee.\n2025/03/04 13:52:47 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: adb-1781258311325241.1.azuredatabricks.net/ml/experiments/1516674257214703.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 6) Log de performance en MLflow. \n",
    "#    Decidir reentrenar si cae < threshold\n",
    "# =========================================================\n",
    "\n",
    "with mlflow.start_run(run_name=\"Monitoring_in_Production\"):\n",
    "    mlflow.log_metric(\"AUC_new\", auc_new)\n",
    "    # mlflow.log_metric(\"drift_mean_diff\", drift_diff)\n",
    "    \n",
    "    # Si la AUC es demasiado baja, se gatilla un \"Retrain\"\n",
    "    # Lo simulamos:\n",
    "    performance_threshold = 0.90  # Ejemplo\n",
    "    if auc_new < performance_threshold:\n",
    "        print(\"⚠️ AUC < threshold, disparar un reentrenamiento.\")\n",
    "        mlflow.set_tag(\"ACTION_NEEDED\", \"Retrain\")\n",
    "        # Podrías invocar un job que reejecute notebook 03, etc.\n",
    "    else:\n",
    "        print(\"✅ Performance aceptable, no se requiere reentrenamiento.\")\n",
    "        mlflow.set_tag(\"ACTION_NEEDED\", \"None\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_Monitoreo_y_Mantenimiento.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}