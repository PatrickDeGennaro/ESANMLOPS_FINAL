# ğŸš€ Proyecto MLOps - PredicciÃ³n de Accidentes en MinerÃ­a

Este repositorio documenta el desarrollo de un modelo de **Machine Learning** para predecir la ocurrencia de accidentes en la industria minera, implementando las mejores prÃ¡cticas de **MLOps** en **Databricks** con **Azure**.

## ğŸ“Œ Estructura del Proyecto

El proyecto estÃ¡ organizado en notebooks de **Databricks**, cada uno representando una fase clave del pipeline **MLOps**:

1. **ğŸ“‚ 01_Ingesta_y_Almacenamiento**  
   - Carga y almacenamiento de datos en **Delta Lake** usando **Unity Catalog**.

2. **ğŸ“Š 02_EDA_Mining_Data**  
   - AnÃ¡lisis exploratorio de datos (**EDA**) para detectar patrones y tendencias.

3. **ğŸ¤– 03_Modelado_Mining_Data**  
   - Entrenamiento de un **Random Forest** en **PySpark MLlib**.  
   - Registro del modelo en **MLflow Model Registry**.

4. **ğŸš€ 04_Despliegue_Modelo**  
   - ImplementaciÃ³n del modelo en **Databricks Serving** como una API REST.

5. **ğŸ”— 05_Prueba_API_Accident_Prediction**  
   - Pruebas del endpoint de la API con solicitudes POST en **Python**.

6. **ğŸ“ˆ 06_Monitoreo_ProducciÃ³n**  
   - EvaluaciÃ³n de mÃ©tricas en producciÃ³n con **MLflow**.  
   - ValidaciÃ³n del rendimiento del modelo.
---

## âš™ï¸ **TecnologÃ­as Utilizadas**
âœ… **Databricks**  
âœ… **MLflow** para experimentaciÃ³n y gestiÃ³n del modelo  
âœ… **PySpark MLlib** para entrenamiento y evaluaciÃ³n  
âœ… **Unity Catalog** para gobernanza de datos  
âœ… **Delta Lake** para almacenamiento eficiente  
âœ… **Azure Databricks Serving** para el despliegue como API REST  

---

## ğŸ“¢ **EjecuciÃ³n del Proyecto en Databricks**
Para correr este pipeline en **Databricks**, sigue estos pasos:

1ï¸âƒ£ **Configura un cluster** con **PySpark 3.5+** y habilita MLflow.  
2ï¸âƒ£ **Carga los notebooks** en Databricks y ejecuta en orden.  
3ï¸âƒ£ **Revisa el API Endpoint** desde **05_Prueba_API_Accident_Prediction**.  



