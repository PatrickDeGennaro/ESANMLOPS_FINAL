#  Proyecto MLOps - Predicci√≥n de Accidentes en Miner√≠a

Este repositorio documenta el desarrollo de un modelo de **Machine Learning** para predecir la ocurrencia de accidentes en la industria minera, implementando las mejores pr√°cticas de **MLOps** en **Databricks** con **Azure**.

## üìå Estructura del Proyecto

El proyecto est√° organizado en notebooks de **Databricks**, cada uno representando una fase clave del pipeline **MLOps**:

1. **01_Ingesta_y_Almacenamiento**  
   - Carga y almacenamiento de datos en **Delta Lake** usando **Unity Catalog**.
2. **02_EDA_Mining_Data**  
   - An√°lisis exploratorio de datos (**EDA**) para detectar patrones y tendencias.
3. **03_Modelado_Mining_Data**  
   - Entrenamiento de un **Random Forest** en **PySpark MLlib**.  
   - Registro del modelo en **MLflow Model Registry**.
4. **04_Despliegue_Modelo**  
   - Implementaci√≥n del modelo en **Databricks Serving** como una API REST.
5. **05_Prueba_API_Accident_Prediction**  
   - Pruebas del endpoint de la API con solicitudes POST en **Python**.
6. **06_Monitoreo_Producci√≥n**  
   - Evaluaci√≥n de m√©tricas en producci√≥n con **MLflow**.  
   - Validaci√≥n del rendimiento del modelo.
---

## ‚öôÔ∏è **Tecnolog√≠as Utilizadas**
‚úÖ **Databricks**  
‚úÖ **MLflow** para experimentaci√≥n y gesti√≥n del modelo  
‚úÖ **PySpark MLlib** para entrenamiento y evaluaci√≥n  
‚úÖ **Unity Catalog** para gobernanza de datos  
‚úÖ **Delta Lake** para almacenamiento eficiente  
‚úÖ **Azure Databricks Serving** para el despliegue como API REST  

---

##  **Ejecuci√≥n del Proyecto en Databricks**
Para correr este pipeline en **Databricks**, sigue estos pasos:

1Ô∏è‚É£ **Configura un cluster** con **PySpark 3.5+** y habilita MLflow.  
2Ô∏è‚É£ **Carga los notebooks** en Databricks y ejecuta en orden.  
3Ô∏è‚É£ **Revisa el API Endpoint** desde **05_Prueba_API_Accident_Prediction**.  



